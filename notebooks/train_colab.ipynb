{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sugarcane Disease Classification Training\n",
    "\n",
    "This notebook trains a YOLOv11n-cls model for sugarcane disease classification.\n",
    "\n",
    "**Model**: YOLOv11n-cls (nano classification - optimized for mobile/edge)\n",
    "\n",
    "**Classes**: Healthy, Mosaic, Redrot, Rust, Yellow\n",
    "\n",
    "**Hardware**: Run this on Google Colab with GPU enabled (Runtime ‚Üí Change runtime type ‚Üí GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q ultralytics kagglehub\n",
    "\n",
    "# Import libraries\n",
    "from ultralytics import YOLO\n",
    "import kagglehub\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Download Dataset\n",
    "\n",
    "‚ö†Ô∏è **Important**: You need Kaggle API credentials:\n",
    "1. Go to https://www.kaggle.com/settings\n",
    "2. Click \"Create New API Token\"\n",
    "3. Upload the `kaggle.json` file to Colab (Files panel on left)\n",
    "4. Run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Kaggle credentials\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "print(\"‚úÖ Kaggle credentials configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "print(\"üì• Downloading sugarcane disease dataset...\")\n",
    "dataset_path = kagglehub.dataset_download(\"nirmalsankalana/sugarcane-leaf-disease-dataset\")\n",
    "print(f\"‚úÖ Dataset downloaded to: {dataset_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Prepare Dataset\n",
    "\n",
    "Organize images into YOLO classification format:\n",
    "```\n",
    "dataset/\n",
    "‚îú‚îÄ‚îÄ train/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Healthy/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Mosaic/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Redrot/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Rust/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ Yellow/\n",
    "‚îú‚îÄ‚îÄ val/\n",
    "‚îî‚îÄ‚îÄ test/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# Configuration\n",
    "CLASS_NAMES = ['Healthy', 'Mosaic', 'Redrot', 'Rust', 'Yellow']\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.2\n",
    "TEST_RATIO = 0.1\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Discover images in the downloaded dataset\n",
    "print(\"üîç Discovering images...\")\n",
    "class_images = defaultdict(list)\n",
    "image_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        if Path(file).suffix.lower() in image_extensions:\n",
    "            file_path = Path(root) / file\n",
    "            folder_name = Path(root).name.lower()\n",
    "            \n",
    "            # Detect class from folder or filename\n",
    "            for class_name in CLASS_NAMES:\n",
    "                if class_name.lower() in folder_name or class_name.lower() in file.lower():\n",
    "                    class_images[class_name].append(file_path)\n",
    "                    break\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nüìä Dataset Statistics:\")\n",
    "for class_name in CLASS_NAMES:\n",
    "    count = len(class_images[class_name])\n",
    "    print(f\"   {class_name}: {count} images\")\n",
    "print(f\"   Total: {sum(len(imgs) for imgs in class_images.values())} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory structure and split dataset\n",
    "output_dir = Path('/content/sugarcane_dataset')\n",
    "\n",
    "print(\"\\n‚úÇÔ∏è  Splitting and organizing dataset...\")\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    for class_name in CLASS_NAMES:\n",
    "        (output_dir / split / class_name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Split and copy images\n",
    "stats = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for class_name, images in class_images.items():\n",
    "    # Shuffle images\n",
    "    shuffled = images.copy()\n",
    "    random.shuffle(shuffled)\n",
    "    \n",
    "    # Calculate split points\n",
    "    total = len(shuffled)\n",
    "    train_end = int(total * TRAIN_RATIO)\n",
    "    val_end = train_end + int(total * VAL_RATIO)\n",
    "    \n",
    "    # Split\n",
    "    splits = {\n",
    "        'train': shuffled[:train_end],\n",
    "        'val': shuffled[train_end:val_end],\n",
    "        'test': shuffled[val_end:]\n",
    "    }\n",
    "    \n",
    "    # Copy images\n",
    "    for split_name, split_images in splits.items():\n",
    "        for img_path in split_images:\n",
    "            dest = output_dir / split_name / class_name / img_path.name\n",
    "            shutil.copy2(img_path, dest)\n",
    "            stats[split_name][class_name] += 1\n",
    "\n",
    "# Print split statistics\n",
    "print(\"\\nüìä Split Statistics:\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    for class_name in CLASS_NAMES:\n",
    "        print(f\"   {class_name}: {stats[split][class_name]} images\")\n",
    "    print(f\"   Total: {sum(stats[split].values())} images\")\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset organized at: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "# Display sample images from each class\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "for idx, class_name in enumerate(CLASS_NAMES):\n",
    "    class_dir = output_dir / 'train' / class_name\n",
    "    sample_img = list(class_dir.glob('*'))[0]\n",
    "    \n",
    "    img = PILImage.open(sample_img)\n",
    "    axes[idx].imshow(img)\n",
    "    axes[idx].set_title(class_name, fontsize=14, fontweight='bold')\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Sample images from each disease class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train YOLOv11n-cls Model\n",
    "\n",
    "**Training Parameters**:\n",
    "- Model: YOLOv11n-cls (nano - optimized for mobile)\n",
    "- Image size: 224x224\n",
    "- Batch size: 64\n",
    "- Epochs: 100 (with early stopping)\n",
    "- Augmentation: Enabled (automatic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "print(\"ü§ñ Loading YOLOv11n-cls pretrained model...\")\n",
    "model = YOLO('yolov11n-cls.pt')\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"üöÄ Starting training...\\n\")\n",
    "\n",
    "results = model.train(\n",
    "    data=str(output_dir),\n",
    "    epochs=100,\n",
    "    imgsz=224,\n",
    "    batch=64,\n",
    "    patience=15,       # Early stopping after 15 epochs without improvement\n",
    "    save=True,\n",
    "    device=0,          # Use GPU 0\n",
    "    workers=8,\n",
    "    optimizer='Adam',\n",
    "    lr0=0.001,\n",
    "    project='sugarcane_disease',\n",
    "    name='yolov11n_cls',\n",
    "    exist_ok=True,\n",
    "    pretrained=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: View Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training curves\n",
    "from IPython.display import Image, display\n",
    "\n",
    "results_dir = Path('sugarcane_disease/yolov11n_cls')\n",
    "\n",
    "print(\"üìà Training Results:\\n\")\n",
    "\n",
    "# Display results image\n",
    "results_img = results_dir / 'results.png'\n",
    "if results_img.exists():\n",
    "    display(Image(filename=str(results_img)))\n",
    "else:\n",
    "    print(\"Results image not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrix\n",
    "confusion_matrix_img = results_dir / 'confusion_matrix_normalized.png'\n",
    "if confusion_matrix_img.exists():\n",
    "    print(\"\\nüìä Confusion Matrix:\\n\")\n",
    "    display(Image(filename=str(confusion_matrix_img)))\n",
    "else:\n",
    "    print(\"Confusion matrix not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Validate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and validate\n",
    "best_model = YOLO(results_dir / 'weights' / 'best.pt')\n",
    "\n",
    "print(\"üîç Validating model on test set...\\n\")\n",
    "metrics = best_model.val(data=str(output_dir), split='test')\n",
    "\n",
    "print(f\"\\nüìä Test Set Performance:\")\n",
    "print(f\"   Accuracy (top1): {metrics.top1:.4f}\")\n",
    "print(f\"   Accuracy (top5): {metrics.top5:.4f}\")\n",
    "print(\"\\n‚úÖ Validation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on sample images from test set\n",
    "test_images = []\n",
    "for class_name in CLASS_NAMES:\n",
    "    class_dir = output_dir / 'test' / class_name\n",
    "    test_images.append(list(class_dir.glob('*'))[0])\n",
    "\n",
    "# Run predictions\n",
    "print(\"üîÆ Running predictions on test samples...\\n\")\n",
    "\n",
    "for img_path in test_images:\n",
    "    results = best_model(img_path, verbose=False)\n",
    "    \n",
    "    # Get prediction\n",
    "    probs = results[0].probs\n",
    "    predicted_class = CLASS_NAMES[probs.top1]\n",
    "    confidence = probs.top1conf.item()\n",
    "    true_class = img_path.parent.name\n",
    "    \n",
    "    # Display result\n",
    "    status = \"‚úÖ\" if predicted_class == true_class else \"‚ùå\"\n",
    "    print(f\"{status} True: {true_class:10} | Predicted: {predicted_class:10} | Confidence: {confidence:.3f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Predictions complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Export Model for Deployment\n",
    "\n",
    "Export to TFLite format for mobile/edge deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to TFLite (for mobile deployment)\n",
    "print(\"üì¶ Exporting model to TFLite format...\\n\")\n",
    "\n",
    "tflite_model = best_model.export(\n",
    "    format='tflite',\n",
    "    imgsz=224,\n",
    "    int8=False,  # Set to True for INT8 quantization (smaller, faster)\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Model exported: {tflite_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to ONNX (alternative format for various platforms)\n",
    "print(\"üì¶ Exporting model to ONNX format...\\n\")\n",
    "\n",
    "onnx_model = best_model.export(\n",
    "    format='onnx',\n",
    "    imgsz=224,\n",
    "    simplify=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Model exported: {onnx_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Download Models\n",
    "\n",
    "Download the trained models to your local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip the results folder for download\n",
    "!zip -r sugarcane_models.zip sugarcane_disease/yolov11n_cls/weights/\n",
    "\n",
    "print(\"\\n‚úÖ Models packaged!\")\n",
    "print(\"\\nüì• Download 'sugarcane_models.zip' from the Files panel (left sidebar)\")\n",
    "print(\"\\nContents:\")\n",
    "print(\"   - best.pt (PyTorch model)\")\n",
    "print(\"   - last.pt (last checkpoint)\")\n",
    "print(\"   - best_saved_model/ (TFLite model)\")\n",
    "print(\"   - best.onnx (ONNX model)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "‚úÖ **Completed Steps**:\n",
    "1. Downloaded sugarcane disease dataset (2,569 images)\n",
    "2. Organized into train/val/test splits\n",
    "3. Trained YOLOv11n-cls model\n",
    "4. Validated on test set\n",
    "5. Exported to TFLite and ONNX formats\n",
    "\n",
    "üöÄ **Next Steps**:\n",
    "1. Download the trained models\n",
    "2. Integrate into your mobile application\n",
    "3. Test on real sugarcane leaves in the field\n",
    "4. Collect more data to improve accuracy\n",
    "\n",
    "üì± **Mobile Integration**:\n",
    "- Use the TFLite model for Android/iOS\n",
    "- Expected inference speed: 30-60 FPS\n",
    "- Model size: ~5 MB\n",
    "\n",
    "üìñ **Resources**:\n",
    "- [Ultralytics YOLO Docs](https://docs.ultralytics.com)\n",
    "- [TFLite Integration Guide](https://www.tensorflow.org/lite)\n",
    "- [YOLO Classification Guide](https://docs.ultralytics.com/tasks/classify/)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
